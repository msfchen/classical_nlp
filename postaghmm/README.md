# Part-of-Speech, POS, Tagging using Viterbi Algorithm

- Goal: to assign the most likely part-of-speech tag (Noun, Verb, Adjective...) to each word in an input word_seq
- Approach: Viterbi algorithm using dynamic programming

  - assigning a part-of-speech tag (Noun, Verb, Adjective...) to each word in an input text
  - explore the preprocessed and POS-tagged training and test corpra; build vocab = { word: idx } from the given hmm_vocab.txt
  - use training_corpus to build emission_counts = {(tag, word):count}, transition_counts = {(prev_tag, tag):count}, tag_counts = {tag:count}; use tag_counts to build states = sorted list of all possible tags
  - POS tag for a word is determined by the (tag, word) of the word in the emission_counts that has the highest count. 
  - create transition probabilities P(t_i|t_i-1) matrix A and emission probabilities P(w_i|t_i) matrix B
  - Viterbi algorithm utilizes dynamic programming, which can be decomposed into 3 steps:
    - initialization: initialize best_paths and best_probs matrices; best_paths: matrix of dimension (num_tags, len(word_seq)) of integers; best_probs: matrix of dimension (num_tags, len(word_seq)) of floats
      - Both matrices will be initialized to zero except for column zero of best_probs. Column zero of best_probs is initialized with the assumption that the first word of the word_seq was preceded by a start token ("--s--"). Reference the A matrix for the transition probability.
      - ğ‘–ğ‘“ğ´[ğ‘ ğ‘–ğ‘‘ğ‘¥,ğ‘–]!=0:ğ‘ğ‘’ğ‘ ğ‘¡_ğ‘ğ‘Ÿğ‘œğ‘ğ‘ [ğ‘–,0]=ğ‘™ğ‘œğ‘”(ğ´[ğ‘ ğ‘–ğ‘‘ğ‘¥,ğ‘–])+ğ‘™ğ‘œğ‘”(ğµ[ğ‘–,ğ‘£ğ‘œğ‘ğ‘ğ‘[word_seq[0]]; ğ‘–ğ‘“ğ´[ğ‘ ğ‘–ğ‘‘ğ‘¥,ğ‘–]==0:ğ‘ğ‘’ğ‘ ğ‘¡_ğ‘ğ‘Ÿğ‘œğ‘ğ‘ [ğ‘–,0]=ğ‘“ğ‘™ğ‘œğ‘ğ‘¡(â€²âˆ’ğ‘–ğ‘›ğ‘“â€²)
    - Viterbi forward
      - compute the probability and path for the ğ‘–ğ‘¡â„ word in the word_seq, the prior word ğ‘–âˆ’1 in the word_seq, current POS tag ğ‘— , and previous POS tag ğ‘˜:
      - prob=ğ›ğğ¬ğ­_ğ©ğ«ğ¨ğ›ğ‘˜,ğ‘–âˆ’1+log(ğ€ğ‘˜,ğ‘—)+log(ğğ‘—,ğ‘£ğ‘œğ‘ğ‘ğ‘(word_seq_ğ‘–)); retain the highest probability computed for the current word as best_prob_i and the corresponding best_path_i = k
    - Viterbi backward
      - The Viterbi backward algorithm gets the predictions of the POS tags for each word in the word_seq using the best_paths and the best_probs matrices.
      - Go through each POS tag for the last word (last column of best_probs) to find the row (POS tag integer ID) with highest probability for the last word
      - Find the best POS tags by walking backward through the best_paths From the last word in the word_seq to the 0th word in the word_seq; return the corresponding POS_tag_seq.
  